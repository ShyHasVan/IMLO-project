{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQl-2CRVuZWS",
        "outputId": "c6a1e233-23a3-4c2a-a782-d707f4d90ee1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to data/flowers-102/102flowers.tgz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▊| 339738624/344862509 [00:20<00:02, 1920225.87it/s]"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "custom_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "training_data = datasets.Flowers102(\n",
        "    root=\"data\",\n",
        "    split= \"train\",\n",
        "    download=True,\n",
        "    transform= custom_transform,\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "\n",
        "test_data = datasets.Flowers102(\n",
        "    root=\"data\",\n",
        "    split= \"test\",\n",
        "    download=True,\n",
        "    transform= custom_transform,\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
        "\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "count=0\n",
        "for i, (X_Train, y_train) in enumerate(training_data):\n",
        "  count+= 1\n",
        "\n",
        "conv1 = nn.Conv2d(3, 18, 3, 1, 'same')\n",
        "conv2 = nn.Conv2d(18, 144, 3, 1, 'same')\n",
        "conv3 = nn.Conv2d(144, 360, 3, 1, 'same')\n",
        "x = F.relu(conv1(X_Train))\n",
        "\n",
        "x = F.max_pool2d(x, 2, 2)\n",
        "x.shape\n",
        "\n",
        "x = F.relu(conv2(x))\n",
        "\n",
        "x = F.max_pool2d(x, 2, 2)\n",
        "x = F.relu(conv3(x))\n",
        "\n",
        "x = F.max_pool2d(x, 2, 2)\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2bp2699ulxj"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.conv1 = nn.Conv2d(3, 9, 3, 1, 'same')\n",
        "        self.conv2 = nn.Conv2d(9, 18, 3, 1, 'same')\n",
        "        #Fully Connected Layer\n",
        "        self.fc1 = nn.Linear(18*56*56, 200)\n",
        "        self.fc2 = nn.Linear(200, 150)\n",
        "        self.fc3 = nn.Linear(150, 102)\n",
        "\n",
        "    def forward(self, X):\n",
        "      x = self.flatten(X)\n",
        "      X = F.relu(self.conv1(X))\n",
        "      X = F.max_pool2d(X,2,2)\n",
        "      #Second Pass\n",
        "      X = F.relu(self.conv2(X))\n",
        "      X = F.max_pool2d(X,2,2)\n",
        "      #Fully Connected Layers\n",
        "      X = X.view(-1, 18*56*56)\n",
        "      X = F.relu(self.fc1(X))\n",
        "      X = F.relu(self.fc2(X))\n",
        "      X = self.fc3(X)\n",
        "      return F.log_softmax(X, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IeYBtuEtEdnD"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(64)\n",
        "model  =  NeuralNetwork()\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOyGjfpDSc85"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    # Set the model to training mode - important for batch normalization and dropout layers\n",
        "    # Unnecessary in this situation but added for best practices\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        if batch % 1 == 0:\n",
        "            loss, current = loss.item(), batch * batch_size + len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    num_batches = len(dataloader)\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            pred = model(x)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            _, predicted = torch.max(pred, 1)\n",
        "            correct += (predicted == y).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oG_ahimLFhhQ"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWZH7JsbPYvq",
        "outputId": "f5a32fc0-9306-4a27-be46-1b3b79d0d856"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 4.632421  [   64/ 1020]\n",
            "loss: 4.728790  [  128/ 1020]\n",
            "loss: 4.807528  [  192/ 1020]\n",
            "loss: 4.737648  [  256/ 1020]\n",
            "loss: 4.646730  [  320/ 1020]\n",
            "loss: 4.665675  [  384/ 1020]\n",
            "loss: 4.775331  [  448/ 1020]\n",
            "loss: 4.666566  [  512/ 1020]\n",
            "loss: 4.619850  [  576/ 1020]\n",
            "loss: 4.611726  [  640/ 1020]\n",
            "loss: 4.597502  [  704/ 1020]\n",
            "loss: 4.623504  [  768/ 1020]\n",
            "loss: 4.622926  [  832/ 1020]\n",
            "loss: 4.589792  [  896/ 1020]\n",
            "loss: 4.602981  [  960/ 1020]\n",
            "loss: 4.629015  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 2.1%, Avg loss: 4.585814 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 4.541603  [   64/ 1020]\n",
            "loss: 4.549908  [  128/ 1020]\n",
            "loss: 4.526780  [  192/ 1020]\n",
            "loss: 4.540767  [  256/ 1020]\n",
            "loss: 4.548572  [  320/ 1020]\n",
            "loss: 4.470823  [  384/ 1020]\n",
            "loss: 4.534067  [  448/ 1020]\n",
            "loss: 4.357556  [  512/ 1020]\n",
            "loss: 4.527840  [  576/ 1020]\n",
            "loss: 4.304918  [  640/ 1020]\n",
            "loss: 4.374347  [  704/ 1020]\n",
            "loss: 4.496682  [  768/ 1020]\n",
            "loss: 4.436764  [  832/ 1020]\n",
            "loss: 4.458569  [  896/ 1020]\n",
            "loss: 4.438516  [  960/ 1020]\n",
            "loss: 4.391532  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 2.8%, Avg loss: 4.388488 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 4.293872  [   64/ 1020]\n",
            "loss: 4.302397  [  128/ 1020]\n",
            "loss: 4.376930  [  192/ 1020]\n",
            "loss: 4.234460  [  256/ 1020]\n",
            "loss: 4.263458  [  320/ 1020]\n",
            "loss: 3.984767  [  384/ 1020]\n",
            "loss: 4.062659  [  448/ 1020]\n",
            "loss: 4.151090  [  512/ 1020]\n",
            "loss: 4.122560  [  576/ 1020]\n",
            "loss: 4.111074  [  640/ 1020]\n",
            "loss: 4.233528  [  704/ 1020]\n",
            "loss: 4.109105  [  768/ 1020]\n",
            "loss: 4.140545  [  832/ 1020]\n",
            "loss: 4.139225  [  896/ 1020]\n",
            "loss: 4.067676  [  960/ 1020]\n",
            "loss: 4.092090  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 3.4%, Avg loss: 4.210434 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 3.983991  [   64/ 1020]\n",
            "loss: 3.974523  [  128/ 1020]\n",
            "loss: 4.183474  [  192/ 1020]\n",
            "loss: 3.925042  [  256/ 1020]\n",
            "loss: 3.898952  [  320/ 1020]\n",
            "loss: 3.748171  [  384/ 1020]\n",
            "loss: 3.906982  [  448/ 1020]\n",
            "loss: 4.075375  [  512/ 1020]\n",
            "loss: 3.908340  [  576/ 1020]\n",
            "loss: 3.801360  [  640/ 1020]\n",
            "loss: 3.987624  [  704/ 1020]\n",
            "loss: 3.858117  [  768/ 1020]\n",
            "loss: 3.850214  [  832/ 1020]\n",
            "loss: 3.970411  [  896/ 1020]\n",
            "loss: 3.972312  [  960/ 1020]\n",
            "loss: 3.843767  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 6.0%, Avg loss: 4.029853 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 3.661981  [   64/ 1020]\n",
            "loss: 3.732137  [  128/ 1020]\n",
            "loss: 3.588350  [  192/ 1020]\n",
            "loss: 3.717437  [  256/ 1020]\n",
            "loss: 3.738578  [  320/ 1020]\n",
            "loss: 3.685113  [  384/ 1020]\n",
            "loss: 3.693251  [  448/ 1020]\n",
            "loss: 3.653510  [  512/ 1020]\n",
            "loss: 3.651818  [  576/ 1020]\n",
            "loss: 3.597482  [  640/ 1020]\n",
            "loss: 4.029201  [  704/ 1020]\n",
            "loss: 3.804196  [  768/ 1020]\n",
            "loss: 3.830206  [  832/ 1020]\n",
            "loss: 3.794099  [  896/ 1020]\n",
            "loss: 3.716051  [  960/ 1020]\n",
            "loss: 3.748359  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 6.9%, Avg loss: 3.935168 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 3.466146  [   64/ 1020]\n",
            "loss: 3.561247  [  128/ 1020]\n",
            "loss: 3.761217  [  192/ 1020]\n",
            "loss: 3.447231  [  256/ 1020]\n",
            "loss: 3.466115  [  320/ 1020]\n",
            "loss: 3.569676  [  384/ 1020]\n",
            "loss: 3.583820  [  448/ 1020]\n",
            "loss: 3.739179  [  512/ 1020]\n",
            "loss: 3.593465  [  576/ 1020]\n",
            "loss: 3.723087  [  640/ 1020]\n",
            "loss: 3.541700  [  704/ 1020]\n",
            "loss: 3.706108  [  768/ 1020]\n",
            "loss: 3.289244  [  832/ 1020]\n",
            "loss: 3.468252  [  896/ 1020]\n",
            "loss: 3.651670  [  960/ 1020]\n",
            "loss: 3.475576  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 11.6%, Avg loss: 3.792750 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 3.271826  [   64/ 1020]\n",
            "loss: 3.324409  [  128/ 1020]\n",
            "loss: 3.067522  [  192/ 1020]\n",
            "loss: 3.588733  [  256/ 1020]\n",
            "loss: 3.763381  [  320/ 1020]\n",
            "loss: 3.420867  [  384/ 1020]\n",
            "loss: 3.576232  [  448/ 1020]\n",
            "loss: 3.417882  [  512/ 1020]\n",
            "loss: 3.729626  [  576/ 1020]\n",
            "loss: 3.100338  [  640/ 1020]\n",
            "loss: 3.281252  [  704/ 1020]\n",
            "loss: 3.572854  [  768/ 1020]\n",
            "loss: 3.438211  [  832/ 1020]\n",
            "loss: 3.406047  [  896/ 1020]\n",
            "loss: 3.346339  [  960/ 1020]\n",
            "loss: 3.371715  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 12.8%, Avg loss: 3.730678 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 3.203040  [   64/ 1020]\n",
            "loss: 3.298651  [  128/ 1020]\n",
            "loss: 2.970955  [  192/ 1020]\n",
            "loss: 3.171139  [  256/ 1020]\n",
            "loss: 3.236941  [  320/ 1020]\n",
            "loss: 3.432387  [  384/ 1020]\n",
            "loss: 3.279188  [  448/ 1020]\n",
            "loss: 3.097183  [  512/ 1020]\n",
            "loss: 3.323667  [  576/ 1020]\n",
            "loss: 2.991359  [  640/ 1020]\n",
            "loss: 3.205487  [  704/ 1020]\n",
            "loss: 3.158354  [  768/ 1020]\n",
            "loss: 3.429135  [  832/ 1020]\n",
            "loss: 3.161773  [  896/ 1020]\n",
            "loss: 3.296157  [  960/ 1020]\n",
            "loss: 3.273264  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 11.1%, Avg loss: 3.754133 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 3.054316  [   64/ 1020]\n",
            "loss: 3.447783  [  128/ 1020]\n",
            "loss: 3.023690  [  192/ 1020]\n",
            "loss: 3.122750  [  256/ 1020]\n",
            "loss: 2.778419  [  320/ 1020]\n",
            "loss: 3.433455  [  384/ 1020]\n",
            "loss: 3.127782  [  448/ 1020]\n",
            "loss: 2.781643  [  512/ 1020]\n",
            "loss: 3.189882  [  576/ 1020]\n",
            "loss: 3.421232  [  640/ 1020]\n",
            "loss: 3.433451  [  704/ 1020]\n",
            "loss: 3.045162  [  768/ 1020]\n",
            "loss: 3.020763  [  832/ 1020]\n",
            "loss: 3.254053  [  896/ 1020]\n",
            "loss: 2.899350  [  960/ 1020]\n",
            "loss: 3.160902  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 11.8%, Avg loss: 3.674198 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 2.924665  [   64/ 1020]\n",
            "loss: 3.313212  [  128/ 1020]\n",
            "loss: 3.222837  [  192/ 1020]\n",
            "loss: 3.031037  [  256/ 1020]\n",
            "loss: 2.987183  [  320/ 1020]\n",
            "loss: 3.087553  [  384/ 1020]\n",
            "loss: 2.984802  [  448/ 1020]\n",
            "loss: 3.207606  [  512/ 1020]\n",
            "loss: 2.864890  [  576/ 1020]\n",
            "loss: 3.065902  [  640/ 1020]\n",
            "loss: 3.256155  [  704/ 1020]\n",
            "loss: 2.855028  [  768/ 1020]\n",
            "loss: 3.323278  [  832/ 1020]\n",
            "loss: 2.910934  [  896/ 1020]\n",
            "loss: 3.228875  [  960/ 1020]\n",
            "loss: 3.073490  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 13.9%, Avg loss: 3.660392 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 2.878083  [   64/ 1020]\n",
            "loss: 2.740902  [  128/ 1020]\n",
            "loss: 2.977140  [  192/ 1020]\n",
            "loss: 2.883583  [  256/ 1020]\n",
            "loss: 2.744335  [  320/ 1020]\n",
            "loss: 3.121415  [  384/ 1020]\n",
            "loss: 3.186160  [  448/ 1020]\n",
            "loss: 3.207206  [  512/ 1020]\n",
            "loss: 3.007918  [  576/ 1020]\n",
            "loss: 3.096728  [  640/ 1020]\n",
            "loss: 2.846639  [  704/ 1020]\n",
            "loss: 3.022103  [  768/ 1020]\n",
            "loss: 3.021922  [  832/ 1020]\n",
            "loss: 2.863347  [  896/ 1020]\n",
            "loss: 2.824257  [  960/ 1020]\n",
            "loss: 2.886134  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 16.4%, Avg loss: 3.552887 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 2.773262  [   64/ 1020]\n",
            "loss: 2.738429  [  128/ 1020]\n",
            "loss: 2.776853  [  192/ 1020]\n",
            "loss: 2.737517  [  256/ 1020]\n",
            "loss: 2.827824  [  320/ 1020]\n",
            "loss: 3.026915  [  384/ 1020]\n",
            "loss: 2.727858  [  448/ 1020]\n",
            "loss: 2.575504  [  512/ 1020]\n",
            "loss: 3.122644  [  576/ 1020]\n",
            "loss: 2.967795  [  640/ 1020]\n",
            "loss: 2.890203  [  704/ 1020]\n",
            "loss: 2.967837  [  768/ 1020]\n",
            "loss: 2.858590  [  832/ 1020]\n",
            "loss: 3.032464  [  896/ 1020]\n",
            "loss: 2.780797  [  960/ 1020]\n",
            "loss: 3.149400  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 16.4%, Avg loss: 3.589898 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 2.746082  [   64/ 1020]\n",
            "loss: 2.512729  [  128/ 1020]\n",
            "loss: 2.539983  [  192/ 1020]\n",
            "loss: 2.926421  [  256/ 1020]\n",
            "loss: 2.852407  [  320/ 1020]\n",
            "loss: 2.687730  [  384/ 1020]\n",
            "loss: 2.782969  [  448/ 1020]\n",
            "loss: 2.968773  [  512/ 1020]\n",
            "loss: 3.083792  [  576/ 1020]\n",
            "loss: 2.892533  [  640/ 1020]\n",
            "loss: 2.981612  [  704/ 1020]\n",
            "loss: 2.315774  [  768/ 1020]\n",
            "loss: 2.582653  [  832/ 1020]\n",
            "loss: 2.898922  [  896/ 1020]\n",
            "loss: 2.686836  [  960/ 1020]\n",
            "loss: 2.786178  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 17.5%, Avg loss: 3.533676 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 2.417359  [   64/ 1020]\n",
            "loss: 2.513927  [  128/ 1020]\n",
            "loss: 2.573246  [  192/ 1020]\n",
            "loss: 2.538634  [  256/ 1020]\n",
            "loss: 2.631786  [  320/ 1020]\n",
            "loss: 2.597079  [  384/ 1020]\n",
            "loss: 2.745196  [  448/ 1020]\n",
            "loss: 2.686636  [  512/ 1020]\n",
            "loss: 2.525145  [  576/ 1020]\n",
            "loss: 2.714288  [  640/ 1020]\n",
            "loss: 2.738154  [  704/ 1020]\n",
            "loss: 2.663337  [  768/ 1020]\n",
            "loss: 2.872217  [  832/ 1020]\n",
            "loss: 2.587554  [  896/ 1020]\n",
            "loss: 2.990675  [  960/ 1020]\n",
            "loss: 2.746748  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 16.3%, Avg loss: 3.600536 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 2.396601  [   64/ 1020]\n",
            "loss: 2.279924  [  128/ 1020]\n",
            "loss: 2.593644  [  192/ 1020]\n",
            "loss: 2.680103  [  256/ 1020]\n",
            "loss: 2.359772  [  320/ 1020]\n",
            "loss: 2.471452  [  384/ 1020]\n",
            "loss: 2.615324  [  448/ 1020]\n",
            "loss: 2.528352  [  512/ 1020]\n",
            "loss: 2.248989  [  576/ 1020]\n",
            "loss: 2.548028  [  640/ 1020]\n",
            "loss: 2.387017  [  704/ 1020]\n",
            "loss: 2.629457  [  768/ 1020]\n",
            "loss: 2.397567  [  832/ 1020]\n",
            "loss: 2.518015  [  896/ 1020]\n",
            "loss: 3.011918  [  960/ 1020]\n",
            "loss: 3.025731  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 19.4%, Avg loss: 3.453588 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 2.161769  [   64/ 1020]\n",
            "loss: 2.313761  [  128/ 1020]\n",
            "loss: 2.426172  [  192/ 1020]\n",
            "loss: 2.541541  [  256/ 1020]\n",
            "loss: 2.441230  [  320/ 1020]\n",
            "loss: 2.437231  [  384/ 1020]\n",
            "loss: 2.464879  [  448/ 1020]\n",
            "loss: 2.319028  [  512/ 1020]\n",
            "loss: 2.822512  [  576/ 1020]\n",
            "loss: 2.605555  [  640/ 1020]\n",
            "loss: 2.737488  [  704/ 1020]\n",
            "loss: 2.492944  [  768/ 1020]\n",
            "loss: 2.792886  [  832/ 1020]\n",
            "loss: 2.425807  [  896/ 1020]\n",
            "loss: 2.534510  [  960/ 1020]\n",
            "loss: 2.422199  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 19.3%, Avg loss: 3.446954 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 2.203674  [   64/ 1020]\n",
            "loss: 2.377704  [  128/ 1020]\n",
            "loss: 2.066749  [  192/ 1020]\n",
            "loss: 2.428301  [  256/ 1020]\n",
            "loss: 2.303493  [  320/ 1020]\n",
            "loss: 2.724399  [  384/ 1020]\n",
            "loss: 2.489807  [  448/ 1020]\n",
            "loss: 2.361610  [  512/ 1020]\n",
            "loss: 2.436270  [  576/ 1020]\n",
            "loss: 2.463287  [  640/ 1020]\n",
            "loss: 2.303804  [  704/ 1020]\n",
            "loss: 2.540255  [  768/ 1020]\n",
            "loss: 2.220352  [  832/ 1020]\n",
            "loss: 2.459878  [  896/ 1020]\n",
            "loss: 2.746691  [  960/ 1020]\n",
            "loss: 2.626865  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 19.9%, Avg loss: 3.497625 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 2.182696  [   64/ 1020]\n",
            "loss: 2.190843  [  128/ 1020]\n",
            "loss: 2.654083  [  192/ 1020]\n",
            "loss: 2.533699  [  256/ 1020]\n",
            "loss: 2.340958  [  320/ 1020]\n",
            "loss: 2.417718  [  384/ 1020]\n",
            "loss: 2.785807  [  448/ 1020]\n",
            "loss: 2.276462  [  512/ 1020]\n",
            "loss: 2.386235  [  576/ 1020]\n",
            "loss: 2.529249  [  640/ 1020]\n",
            "loss: 2.228932  [  704/ 1020]\n",
            "loss: 1.957039  [  768/ 1020]\n",
            "loss: 2.420077  [  832/ 1020]\n",
            "loss: 2.768734  [  896/ 1020]\n",
            "loss: 2.392431  [  960/ 1020]\n",
            "loss: 2.371119  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 21.4%, Avg loss: 3.380273 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 2.417828  [   64/ 1020]\n",
            "loss: 2.193375  [  128/ 1020]\n",
            "loss: 2.073547  [  192/ 1020]\n",
            "loss: 2.045246  [  256/ 1020]\n",
            "loss: 2.178411  [  320/ 1020]\n",
            "loss: 2.134794  [  384/ 1020]\n",
            "loss: 2.268266  [  448/ 1020]\n",
            "loss: 2.244563  [  512/ 1020]\n",
            "loss: 2.232644  [  576/ 1020]\n",
            "loss: 2.726268  [  640/ 1020]\n",
            "loss: 2.203184  [  704/ 1020]\n",
            "loss: 2.325384  [  768/ 1020]\n",
            "loss: 2.610439  [  832/ 1020]\n",
            "loss: 2.259326  [  896/ 1020]\n",
            "loss: 2.484938  [  960/ 1020]\n",
            "loss: 2.294570  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 21.8%, Avg loss: 3.458007 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 2.012439  [   64/ 1020]\n",
            "loss: 2.085342  [  128/ 1020]\n",
            "loss: 2.610194  [  192/ 1020]\n",
            "loss: 2.196109  [  256/ 1020]\n",
            "loss: 2.458985  [  320/ 1020]\n",
            "loss: 2.636512  [  384/ 1020]\n",
            "loss: 2.139258  [  448/ 1020]\n",
            "loss: 2.107799  [  512/ 1020]\n",
            "loss: 1.925061  [  576/ 1020]\n",
            "loss: 2.272223  [  640/ 1020]\n",
            "loss: 2.493781  [  704/ 1020]\n",
            "loss: 2.337656  [  768/ 1020]\n",
            "loss: 2.167293  [  832/ 1020]\n",
            "loss: 2.656584  [  896/ 1020]\n",
            "loss: 2.561950  [  960/ 1020]\n",
            "loss: 2.519758  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 21.9%, Avg loss: 3.364739 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 2.297778  [   64/ 1020]\n",
            "loss: 1.870900  [  128/ 1020]\n",
            "loss: 2.110767  [  192/ 1020]\n",
            "loss: 2.535968  [  256/ 1020]\n",
            "loss: 2.069397  [  320/ 1020]\n",
            "loss: 2.014093  [  384/ 1020]\n",
            "loss: 2.268782  [  448/ 1020]\n",
            "loss: 2.275137  [  512/ 1020]\n",
            "loss: 2.189006  [  576/ 1020]\n",
            "loss: 2.273135  [  640/ 1020]\n",
            "loss: 2.285323  [  704/ 1020]\n",
            "loss: 2.259482  [  768/ 1020]\n",
            "loss: 2.395603  [  832/ 1020]\n",
            "loss: 2.098411  [  896/ 1020]\n",
            "loss: 2.331855  [  960/ 1020]\n",
            "loss: 2.115064  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 21.1%, Avg loss: 3.511512 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 2.159095  [   64/ 1020]\n",
            "loss: 2.005307  [  128/ 1020]\n",
            "loss: 1.680501  [  192/ 1020]\n",
            "loss: 2.315907  [  256/ 1020]\n",
            "loss: 1.875865  [  320/ 1020]\n",
            "loss: 1.918108  [  384/ 1020]\n",
            "loss: 2.615241  [  448/ 1020]\n",
            "loss: 2.501528  [  512/ 1020]\n",
            "loss: 2.351004  [  576/ 1020]\n",
            "loss: 2.238046  [  640/ 1020]\n",
            "loss: 2.464810  [  704/ 1020]\n",
            "loss: 2.294138  [  768/ 1020]\n",
            "loss: 2.388655  [  832/ 1020]\n",
            "loss: 2.326640  [  896/ 1020]\n",
            "loss: 2.467740  [  960/ 1020]\n",
            "loss: 2.461926  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 23.0%, Avg loss: 3.454841 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 2.022754  [   64/ 1020]\n",
            "loss: 2.220098  [  128/ 1020]\n",
            "loss: 2.199336  [  192/ 1020]\n",
            "loss: 1.765878  [  256/ 1020]\n",
            "loss: 2.234303  [  320/ 1020]\n",
            "loss: 1.899950  [  384/ 1020]\n",
            "loss: 2.352579  [  448/ 1020]\n",
            "loss: 2.147541  [  512/ 1020]\n",
            "loss: 2.215229  [  576/ 1020]\n",
            "loss: 2.498832  [  640/ 1020]\n",
            "loss: 2.055013  [  704/ 1020]\n",
            "loss: 2.509739  [  768/ 1020]\n",
            "loss: 1.774687  [  832/ 1020]\n",
            "loss: 2.242618  [  896/ 1020]\n",
            "loss: 2.138079  [  960/ 1020]\n",
            "loss: 1.736964  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 22.8%, Avg loss: 3.423308 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 1.925892  [   64/ 1020]\n",
            "loss: 1.808856  [  128/ 1020]\n",
            "loss: 1.748569  [  192/ 1020]\n",
            "loss: 1.967152  [  256/ 1020]\n",
            "loss: 1.910353  [  320/ 1020]\n",
            "loss: 2.247236  [  384/ 1020]\n",
            "loss: 2.212613  [  448/ 1020]\n",
            "loss: 1.886536  [  512/ 1020]\n",
            "loss: 1.906248  [  576/ 1020]\n",
            "loss: 2.029090  [  640/ 1020]\n",
            "loss: 2.111106  [  704/ 1020]\n",
            "loss: 2.315591  [  768/ 1020]\n",
            "loss: 1.998678  [  832/ 1020]\n",
            "loss: 2.268881  [  896/ 1020]\n",
            "loss: 2.219260  [  960/ 1020]\n",
            "loss: 2.238596  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 23.9%, Avg loss: 3.364838 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 1.943520  [   64/ 1020]\n",
            "loss: 2.045516  [  128/ 1020]\n",
            "loss: 1.998138  [  192/ 1020]\n",
            "loss: 2.238416  [  256/ 1020]\n",
            "loss: 2.009538  [  320/ 1020]\n",
            "loss: 2.242631  [  384/ 1020]\n",
            "loss: 2.023115  [  448/ 1020]\n",
            "loss: 2.140330  [  512/ 1020]\n",
            "loss: 1.787602  [  576/ 1020]\n",
            "loss: 2.072705  [  640/ 1020]\n",
            "loss: 1.987950  [  704/ 1020]\n",
            "loss: 2.002737  [  768/ 1020]\n",
            "loss: 2.121832  [  832/ 1020]\n",
            "loss: 2.104586  [  896/ 1020]\n",
            "loss: 1.830841  [  960/ 1020]\n",
            "loss: 1.699096  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 24.5%, Avg loss: 3.441798 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 2.095520  [   64/ 1020]\n",
            "loss: 1.723953  [  128/ 1020]\n",
            "loss: 1.993921  [  192/ 1020]\n",
            "loss: 2.294022  [  256/ 1020]\n",
            "loss: 1.952291  [  320/ 1020]\n",
            "loss: 1.777817  [  384/ 1020]\n",
            "loss: 2.054648  [  448/ 1020]\n",
            "loss: 2.273977  [  512/ 1020]\n",
            "loss: 1.935820  [  576/ 1020]\n",
            "loss: 2.140027  [  640/ 1020]\n",
            "loss: 1.915546  [  704/ 1020]\n",
            "loss: 2.272570  [  768/ 1020]\n",
            "loss: 2.149542  [  832/ 1020]\n",
            "loss: 2.052958  [  896/ 1020]\n",
            "loss: 1.617649  [  960/ 1020]\n",
            "loss: 2.104868  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 24.8%, Avg loss: 3.423593 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 1.709976  [   64/ 1020]\n",
            "loss: 1.892405  [  128/ 1020]\n",
            "loss: 1.790276  [  192/ 1020]\n",
            "loss: 1.565760  [  256/ 1020]\n",
            "loss: 1.583703  [  320/ 1020]\n",
            "loss: 1.886564  [  384/ 1020]\n",
            "loss: 1.916273  [  448/ 1020]\n",
            "loss: 1.931921  [  512/ 1020]\n",
            "loss: 1.583075  [  576/ 1020]\n",
            "loss: 1.956992  [  640/ 1020]\n",
            "loss: 2.008602  [  704/ 1020]\n",
            "loss: 1.928366  [  768/ 1020]\n",
            "loss: 1.996949  [  832/ 1020]\n",
            "loss: 1.971290  [  896/ 1020]\n",
            "loss: 1.720425  [  960/ 1020]\n",
            "loss: 1.889626  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 23.6%, Avg loss: 3.505598 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 1.979634  [   64/ 1020]\n",
            "loss: 1.614797  [  128/ 1020]\n",
            "loss: 1.950883  [  192/ 1020]\n",
            "loss: 1.666619  [  256/ 1020]\n",
            "loss: 1.708273  [  320/ 1020]\n",
            "loss: 1.827005  [  384/ 1020]\n",
            "loss: 1.797364  [  448/ 1020]\n",
            "loss: 1.940417  [  512/ 1020]\n",
            "loss: 2.136245  [  576/ 1020]\n",
            "loss: 1.759253  [  640/ 1020]\n",
            "loss: 2.102443  [  704/ 1020]\n",
            "loss: 1.737170  [  768/ 1020]\n",
            "loss: 1.596168  [  832/ 1020]\n",
            "loss: 1.568411  [  896/ 1020]\n",
            "loss: 2.194559  [  960/ 1020]\n",
            "loss: 1.969517  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 26.0%, Avg loss: 3.416067 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 1.739387  [   64/ 1020]\n",
            "loss: 1.927219  [  128/ 1020]\n",
            "loss: 1.468743  [  192/ 1020]\n",
            "loss: 1.514527  [  256/ 1020]\n",
            "loss: 1.968019  [  320/ 1020]\n",
            "loss: 1.883862  [  384/ 1020]\n",
            "loss: 1.842662  [  448/ 1020]\n",
            "loss: 1.832764  [  512/ 1020]\n",
            "loss: 2.037337  [  576/ 1020]\n",
            "loss: 1.894621  [  640/ 1020]\n",
            "loss: 1.995093  [  704/ 1020]\n",
            "loss: 2.112255  [  768/ 1020]\n",
            "loss: 1.722773  [  832/ 1020]\n",
            "loss: 1.652865  [  896/ 1020]\n",
            "loss: 1.665924  [  960/ 1020]\n",
            "loss: 2.230223  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 23.6%, Avg loss: 3.619701 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 1.585142  [   64/ 1020]\n",
            "loss: 1.431873  [  128/ 1020]\n",
            "loss: 1.681620  [  192/ 1020]\n",
            "loss: 1.777324  [  256/ 1020]\n",
            "loss: 1.759597  [  320/ 1020]\n",
            "loss: 1.659737  [  384/ 1020]\n",
            "loss: 1.613298  [  448/ 1020]\n",
            "loss: 1.906801  [  512/ 1020]\n",
            "loss: 1.509212  [  576/ 1020]\n",
            "loss: 1.901493  [  640/ 1020]\n",
            "loss: 1.894330  [  704/ 1020]\n",
            "loss: 1.789039  [  768/ 1020]\n",
            "loss: 1.850688  [  832/ 1020]\n",
            "loss: 2.070991  [  896/ 1020]\n",
            "loss: 2.266281  [  960/ 1020]\n",
            "loss: 1.806404  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 24.9%, Avg loss: 3.453000 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 1.334242  [   64/ 1020]\n",
            "loss: 1.746845  [  128/ 1020]\n",
            "loss: 1.993013  [  192/ 1020]\n",
            "loss: 1.468503  [  256/ 1020]\n",
            "loss: 1.657910  [  320/ 1020]\n",
            "loss: 1.747091  [  384/ 1020]\n",
            "loss: 1.613013  [  448/ 1020]\n",
            "loss: 1.443544  [  512/ 1020]\n",
            "loss: 1.521027  [  576/ 1020]\n",
            "loss: 1.724328  [  640/ 1020]\n",
            "loss: 1.750529  [  704/ 1020]\n",
            "loss: 1.858080  [  768/ 1020]\n",
            "loss: 1.536512  [  832/ 1020]\n",
            "loss: 1.829376  [  896/ 1020]\n",
            "loss: 1.899609  [  960/ 1020]\n",
            "loss: 1.596833  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 25.7%, Avg loss: 3.542399 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 1.772702  [   64/ 1020]\n",
            "loss: 1.832436  [  128/ 1020]\n",
            "loss: 1.945854  [  192/ 1020]\n",
            "loss: 1.734238  [  256/ 1020]\n",
            "loss: 1.802877  [  320/ 1020]\n",
            "loss: 1.872328  [  384/ 1020]\n",
            "loss: 2.053878  [  448/ 1020]\n",
            "loss: 1.934838  [  512/ 1020]\n",
            "loss: 1.633384  [  576/ 1020]\n",
            "loss: 1.631188  [  640/ 1020]\n",
            "loss: 1.738746  [  704/ 1020]\n",
            "loss: 1.690325  [  768/ 1020]\n",
            "loss: 2.210678  [  832/ 1020]\n",
            "loss: 1.841071  [  896/ 1020]\n",
            "loss: 2.126095  [  960/ 1020]\n",
            "loss: 1.617208  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 22.7%, Avg loss: 3.663181 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 1.459251  [   64/ 1020]\n",
            "loss: 2.009272  [  128/ 1020]\n",
            "loss: 1.659302  [  192/ 1020]\n",
            "loss: 1.776955  [  256/ 1020]\n",
            "loss: 1.547367  [  320/ 1020]\n",
            "loss: 1.622070  [  384/ 1020]\n",
            "loss: 1.760306  [  448/ 1020]\n",
            "loss: 1.411920  [  512/ 1020]\n",
            "loss: 1.773039  [  576/ 1020]\n",
            "loss: 1.697729  [  640/ 1020]\n",
            "loss: 1.543072  [  704/ 1020]\n",
            "loss: 1.915929  [  768/ 1020]\n",
            "loss: 1.896357  [  832/ 1020]\n",
            "loss: 1.426958  [  896/ 1020]\n",
            "loss: 1.783692  [  960/ 1020]\n",
            "loss: 1.714505  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 24.6%, Avg loss: 3.513077 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 1.560354  [   64/ 1020]\n",
            "loss: 1.365254  [  128/ 1020]\n",
            "loss: 1.939861  [  192/ 1020]\n",
            "loss: 1.519631  [  256/ 1020]\n",
            "loss: 1.759136  [  320/ 1020]\n",
            "loss: 1.801549  [  384/ 1020]\n",
            "loss: 1.252553  [  448/ 1020]\n",
            "loss: 2.021779  [  512/ 1020]\n",
            "loss: 1.723048  [  576/ 1020]\n",
            "loss: 1.754982  [  640/ 1020]\n",
            "loss: 1.764993  [  704/ 1020]\n",
            "loss: 1.532889  [  768/ 1020]\n",
            "loss: 1.844987  [  832/ 1020]\n",
            "loss: 1.554121  [  896/ 1020]\n",
            "loss: 1.814068  [  960/ 1020]\n",
            "loss: 1.743911  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 25.5%, Avg loss: 3.581313 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 1.461367  [   64/ 1020]\n",
            "loss: 1.455267  [  128/ 1020]\n",
            "loss: 1.622260  [  192/ 1020]\n",
            "loss: 1.580688  [  256/ 1020]\n",
            "loss: 1.418908  [  320/ 1020]\n",
            "loss: 1.697097  [  384/ 1020]\n",
            "loss: 1.494933  [  448/ 1020]\n",
            "loss: 1.891282  [  512/ 1020]\n",
            "loss: 1.305178  [  576/ 1020]\n",
            "loss: 1.645831  [  640/ 1020]\n",
            "loss: 1.610395  [  704/ 1020]\n",
            "loss: 1.537659  [  768/ 1020]\n",
            "loss: 1.325865  [  832/ 1020]\n",
            "loss: 1.905198  [  896/ 1020]\n",
            "loss: 1.842824  [  960/ 1020]\n",
            "loss: 1.939888  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 26.4%, Avg loss: 3.563194 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 1.773175  [   64/ 1020]\n",
            "loss: 1.597406  [  128/ 1020]\n",
            "loss: 1.544296  [  192/ 1020]\n",
            "loss: 1.512871  [  256/ 1020]\n",
            "loss: 1.559696  [  320/ 1020]\n",
            "loss: 1.419229  [  384/ 1020]\n",
            "loss: 1.369708  [  448/ 1020]\n",
            "loss: 1.382314  [  512/ 1020]\n",
            "loss: 1.334864  [  576/ 1020]\n",
            "loss: 1.576318  [  640/ 1020]\n",
            "loss: 1.431044  [  704/ 1020]\n",
            "loss: 1.372345  [  768/ 1020]\n",
            "loss: 1.407666  [  832/ 1020]\n",
            "loss: 1.591857  [  896/ 1020]\n",
            "loss: 1.893531  [  960/ 1020]\n",
            "loss: 1.904975  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 26.4%, Avg loss: 3.627934 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 1.637331  [   64/ 1020]\n",
            "loss: 1.219445  [  128/ 1020]\n",
            "loss: 1.797005  [  192/ 1020]\n",
            "loss: 1.575696  [  256/ 1020]\n",
            "loss: 1.399886  [  320/ 1020]\n",
            "loss: 1.640779  [  384/ 1020]\n",
            "loss: 1.437298  [  448/ 1020]\n",
            "loss: 1.451507  [  512/ 1020]\n",
            "loss: 1.656098  [  576/ 1020]\n",
            "loss: 1.603442  [  640/ 1020]\n",
            "loss: 1.260406  [  704/ 1020]\n",
            "loss: 1.300914  [  768/ 1020]\n",
            "loss: 1.873601  [  832/ 1020]\n",
            "loss: 1.390067  [  896/ 1020]\n",
            "loss: 1.497268  [  960/ 1020]\n",
            "loss: 1.556732  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 25.8%, Avg loss: 3.718927 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 1.749604  [   64/ 1020]\n",
            "loss: 1.696023  [  128/ 1020]\n",
            "loss: 1.449440  [  192/ 1020]\n",
            "loss: 1.534692  [  256/ 1020]\n",
            "loss: 1.573784  [  320/ 1020]\n",
            "loss: 2.002825  [  384/ 1020]\n",
            "loss: 1.818200  [  448/ 1020]\n",
            "loss: 1.543759  [  512/ 1020]\n",
            "loss: 1.787165  [  576/ 1020]\n",
            "loss: 1.625721  [  640/ 1020]\n",
            "loss: 1.599922  [  704/ 1020]\n",
            "loss: 1.468737  [  768/ 1020]\n",
            "loss: 1.644397  [  832/ 1020]\n",
            "loss: 1.692018  [  896/ 1020]\n",
            "loss: 1.573734  [  960/ 1020]\n",
            "loss: 1.392458  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 25.9%, Avg loss: 3.735032 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 1.344861  [   64/ 1020]\n",
            "loss: 1.023125  [  128/ 1020]\n",
            "loss: 1.410091  [  192/ 1020]\n",
            "loss: 1.253457  [  256/ 1020]\n",
            "loss: 1.464402  [  320/ 1020]\n",
            "loss: 1.536125  [  384/ 1020]\n",
            "loss: 1.571109  [  448/ 1020]\n",
            "loss: 1.651250  [  512/ 1020]\n",
            "loss: 1.550481  [  576/ 1020]\n",
            "loss: 1.602816  [  640/ 1020]\n",
            "loss: 1.420740  [  704/ 1020]\n",
            "loss: 1.508235  [  768/ 1020]\n",
            "loss: 1.256314  [  832/ 1020]\n",
            "loss: 1.774346  [  896/ 1020]\n",
            "loss: 1.787262  [  960/ 1020]\n",
            "loss: 1.683513  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 26.5%, Avg loss: 3.708840 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 1.745541  [   64/ 1020]\n",
            "loss: 1.836130  [  128/ 1020]\n",
            "loss: 1.155154  [  192/ 1020]\n",
            "loss: 1.204574  [  256/ 1020]\n",
            "loss: 1.147154  [  320/ 1020]\n",
            "loss: 1.294955  [  384/ 1020]\n",
            "loss: 1.647577  [  448/ 1020]\n",
            "loss: 1.346027  [  512/ 1020]\n",
            "loss: 1.558900  [  576/ 1020]\n",
            "loss: 1.491636  [  640/ 1020]\n",
            "loss: 1.641859  [  704/ 1020]\n",
            "loss: 1.550133  [  768/ 1020]\n",
            "loss: 1.232047  [  832/ 1020]\n",
            "loss: 1.644385  [  896/ 1020]\n",
            "loss: 1.708253  [  960/ 1020]\n",
            "loss: 1.805452  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 26.1%, Avg loss: 3.690385 \n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "loss: 1.343887  [   64/ 1020]\n",
            "loss: 1.320275  [  128/ 1020]\n",
            "loss: 1.617395  [  192/ 1020]\n",
            "loss: 1.412050  [  256/ 1020]\n",
            "loss: 1.298554  [  320/ 1020]\n",
            "loss: 1.351723  [  384/ 1020]\n",
            "loss: 1.565298  [  448/ 1020]\n",
            "loss: 1.505195  [  512/ 1020]\n",
            "loss: 1.370501  [  576/ 1020]\n",
            "loss: 1.390534  [  640/ 1020]\n",
            "loss: 1.682050  [  704/ 1020]\n",
            "loss: 1.535844  [  768/ 1020]\n",
            "loss: 1.357092  [  832/ 1020]\n",
            "loss: 1.555997  [  896/ 1020]\n",
            "loss: 1.603840  [  960/ 1020]\n",
            "loss: 1.781416  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 27.5%, Avg loss: 3.674253 \n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "loss: 1.114599  [   64/ 1020]\n",
            "loss: 1.387212  [  128/ 1020]\n",
            "loss: 1.406605  [  192/ 1020]\n",
            "loss: 1.454477  [  256/ 1020]\n",
            "loss: 1.699673  [  320/ 1020]\n",
            "loss: 1.385964  [  384/ 1020]\n",
            "loss: 1.823214  [  448/ 1020]\n",
            "loss: 1.535094  [  512/ 1020]\n",
            "loss: 1.548652  [  576/ 1020]\n",
            "loss: 1.541527  [  640/ 1020]\n",
            "loss: 1.655593  [  704/ 1020]\n",
            "loss: 1.573102  [  768/ 1020]\n",
            "loss: 1.112228  [  832/ 1020]\n",
            "loss: 1.515147  [  896/ 1020]\n",
            "loss: 1.629052  [  960/ 1020]\n",
            "loss: 1.199590  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 27.1%, Avg loss: 3.714662 \n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "loss: 1.191363  [   64/ 1020]\n",
            "loss: 1.393719  [  128/ 1020]\n",
            "loss: 1.029574  [  192/ 1020]\n",
            "loss: 1.061892  [  256/ 1020]\n",
            "loss: 1.525754  [  320/ 1020]\n",
            "loss: 1.306579  [  384/ 1020]\n",
            "loss: 1.514168  [  448/ 1020]\n",
            "loss: 1.122927  [  512/ 1020]\n",
            "loss: 1.510171  [  576/ 1020]\n",
            "loss: 1.397499  [  640/ 1020]\n",
            "loss: 1.272997  [  704/ 1020]\n",
            "loss: 1.300465  [  768/ 1020]\n",
            "loss: 1.336141  [  832/ 1020]\n",
            "loss: 1.461997  [  896/ 1020]\n",
            "loss: 1.358161  [  960/ 1020]\n",
            "loss: 1.228894  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 26.2%, Avg loss: 3.760422 \n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "loss: 1.872089  [   64/ 1020]\n",
            "loss: 1.243110  [  128/ 1020]\n",
            "loss: 1.490516  [  192/ 1020]\n",
            "loss: 1.221511  [  256/ 1020]\n",
            "loss: 1.267737  [  320/ 1020]\n",
            "loss: 1.461437  [  384/ 1020]\n",
            "loss: 1.238398  [  448/ 1020]\n",
            "loss: 1.485207  [  512/ 1020]\n",
            "loss: 1.560455  [  576/ 1020]\n",
            "loss: 1.362825  [  640/ 1020]\n",
            "loss: 1.368398  [  704/ 1020]\n",
            "loss: 1.733723  [  768/ 1020]\n",
            "loss: 1.115787  [  832/ 1020]\n",
            "loss: 1.299090  [  896/ 1020]\n",
            "loss: 1.900723  [  960/ 1020]\n",
            "loss: 1.195522  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 26.8%, Avg loss: 3.746249 \n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "loss: 1.561493  [   64/ 1020]\n",
            "loss: 1.146819  [  128/ 1020]\n",
            "loss: 1.032484  [  192/ 1020]\n",
            "loss: 1.316046  [  256/ 1020]\n",
            "loss: 1.177441  [  320/ 1020]\n",
            "loss: 1.687787  [  384/ 1020]\n",
            "loss: 1.132013  [  448/ 1020]\n",
            "loss: 1.408949  [  512/ 1020]\n",
            "loss: 1.203555  [  576/ 1020]\n",
            "loss: 1.005763  [  640/ 1020]\n",
            "loss: 1.483118  [  704/ 1020]\n",
            "loss: 1.179616  [  768/ 1020]\n",
            "loss: 1.186669  [  832/ 1020]\n",
            "loss: 1.670064  [  896/ 1020]\n",
            "loss: 1.276043  [  960/ 1020]\n",
            "loss: 1.406637  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 25.5%, Avg loss: 3.891103 \n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "loss: 1.191739  [   64/ 1020]\n",
            "loss: 1.637491  [  128/ 1020]\n",
            "loss: 1.540214  [  192/ 1020]\n",
            "loss: 1.186211  [  256/ 1020]\n",
            "loss: 1.199934  [  320/ 1020]\n",
            "loss: 1.600038  [  384/ 1020]\n",
            "loss: 1.182949  [  448/ 1020]\n",
            "loss: 1.355358  [  512/ 1020]\n",
            "loss: 1.199432  [  576/ 1020]\n",
            "loss: 1.450988  [  640/ 1020]\n",
            "loss: 1.946749  [  704/ 1020]\n",
            "loss: 1.433064  [  768/ 1020]\n",
            "loss: 1.375359  [  832/ 1020]\n",
            "loss: 1.303629  [  896/ 1020]\n",
            "loss: 1.025329  [  960/ 1020]\n",
            "loss: 1.184008  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 27.0%, Avg loss: 3.817614 \n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "loss: 1.000592  [   64/ 1020]\n",
            "loss: 1.254702  [  128/ 1020]\n",
            "loss: 1.205397  [  192/ 1020]\n",
            "loss: 0.936545  [  256/ 1020]\n",
            "loss: 1.465670  [  320/ 1020]\n",
            "loss: 1.136245  [  384/ 1020]\n",
            "loss: 1.071908  [  448/ 1020]\n",
            "loss: 1.211900  [  512/ 1020]\n",
            "loss: 1.351467  [  576/ 1020]\n",
            "loss: 1.682269  [  640/ 1020]\n",
            "loss: 1.295757  [  704/ 1020]\n",
            "loss: 1.337628  [  768/ 1020]\n",
            "loss: 1.495587  [  832/ 1020]\n",
            "loss: 1.148613  [  896/ 1020]\n",
            "loss: 1.407857  [  960/ 1020]\n",
            "loss: 1.625879  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 26.9%, Avg loss: 3.988908 \n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "loss: 1.150237  [   64/ 1020]\n",
            "loss: 1.346455  [  128/ 1020]\n",
            "loss: 1.261144  [  192/ 1020]\n",
            "loss: 1.304454  [  256/ 1020]\n",
            "loss: 1.287276  [  320/ 1020]\n",
            "loss: 1.256483  [  384/ 1020]\n",
            "loss: 1.499564  [  448/ 1020]\n",
            "loss: 1.365443  [  512/ 1020]\n",
            "loss: 1.077168  [  576/ 1020]\n",
            "loss: 1.294989  [  640/ 1020]\n",
            "loss: 1.066732  [  704/ 1020]\n",
            "loss: 1.574050  [  768/ 1020]\n",
            "loss: 1.273592  [  832/ 1020]\n",
            "loss: 1.672395  [  896/ 1020]\n",
            "loss: 1.042161  [  960/ 1020]\n",
            "loss: 1.616732  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 27.8%, Avg loss: 3.861702 \n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "loss: 1.355873  [   64/ 1020]\n",
            "loss: 1.236387  [  128/ 1020]\n",
            "loss: 1.421457  [  192/ 1020]\n",
            "loss: 0.976348  [  256/ 1020]\n",
            "loss: 1.398891  [  320/ 1020]\n",
            "loss: 1.153317  [  384/ 1020]\n",
            "loss: 1.399025  [  448/ 1020]\n",
            "loss: 1.444993  [  512/ 1020]\n",
            "loss: 1.086822  [  576/ 1020]\n",
            "loss: 1.382877  [  640/ 1020]\n",
            "loss: 1.185817  [  704/ 1020]\n",
            "loss: 1.348740  [  768/ 1020]\n",
            "loss: 1.145448  [  832/ 1020]\n",
            "loss: 1.204660  [  896/ 1020]\n",
            "loss: 1.222566  [  960/ 1020]\n",
            "loss: 1.508448  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 26.6%, Avg loss: 3.982055 \n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "loss: 1.173768  [   64/ 1020]\n",
            "loss: 1.465875  [  128/ 1020]\n",
            "loss: 0.998250  [  192/ 1020]\n",
            "loss: 1.367397  [  256/ 1020]\n",
            "loss: 1.109368  [  320/ 1020]\n",
            "loss: 1.178873  [  384/ 1020]\n",
            "loss: 1.258517  [  448/ 1020]\n",
            "loss: 1.532794  [  512/ 1020]\n",
            "loss: 1.509892  [  576/ 1020]\n",
            "loss: 1.705454  [  640/ 1020]\n",
            "loss: 0.972693  [  704/ 1020]\n",
            "loss: 1.475824  [  768/ 1020]\n",
            "loss: 1.098880  [  832/ 1020]\n",
            "loss: 1.611554  [  896/ 1020]\n",
            "loss: 1.352090  [  960/ 1020]\n",
            "loss: 1.419170  [ 1020/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 27.0%, Avg loss: 3.894627 \n",
            "\n",
            "Done!\n",
            "Training took: 52.393042806784315 minutes!\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start = time.time()\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 50\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")\n",
        "\n",
        "end = time.time()\n",
        "total = end - start\n",
        "print(f\"Training took: {total/60} minutes!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}